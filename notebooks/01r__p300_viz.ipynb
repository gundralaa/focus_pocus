{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# P300 Load and Visualize Data\n",
        "\n",
        "This example demonstrates loading, organizing, and visualizing ERP response data from the visual P300 experiment. The experiment uses a visual oddball paradigm. Images of cats and dogs are shwn in a rapid serial visual presentation (RSVP) stream, with cats and dogs categorized respectively as 'targets' or 'non-targets', according to which has high or low probability of occurring, respectively. \n",
        "\n",
        "The data used is the first subject and first session of the one of the eeg-notebooks P300 example datasets, recorded using the InteraXon MUSE EEG headset (2016 model). This session consists of six two-minute blocks of continuous recording.  \n",
        "\n",
        "We first use the `fetch_datasets` to obtain a list of filenames. If these files are not already present \n",
        "in the specified data directory, they will be quickly downloaded from the cloud. \n",
        "\n",
        "After loading the data, we place it in an MNE `Epochs` object, and obtain the trial-averaged response. \n",
        "\n",
        "The final figure plotted at the end shows the P300 response ERP waveform. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'eegnb'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [13], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmne\u001b[39;00m \u001b[39mimport\u001b[39;00m Epochs,find_events\n\u001b[1;32m     14\u001b[0m \u001b[39m# EEG-Notebooks functions\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39meegnb\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39manalysis\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m load_data,plot_conditions\n\u001b[1;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39meegnb\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m fetch_dataset\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'eegnb'"
          ]
        }
      ],
      "source": [
        "# Some standard pythonic imports\n",
        "import os\n",
        "from collections import OrderedDict\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from typing import Union\n",
        "\n",
        "import requests, zipfile, gdown\n",
        "\n",
        "# MNE functions\n",
        "from mne import Epochs,find_events\n",
        "\n",
        "# EEG-Notebooks functions\n",
        "# from eegnb.analysis.utils import load_data,plot_conditions\n",
        "# from eegnb.datasets import fetch_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load eegnb: `fetch_dataset` and `load_data`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'RawArray' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [14], line 159\u001b[0m\n\u001b[1;32m    145\u001b[0m                         fnames \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m fpaths\n\u001b[1;32m    147\u001b[0m     \u001b[39mreturn\u001b[39;00m fnames\n\u001b[1;32m    149\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_data\u001b[39m(\n\u001b[1;32m    150\u001b[0m     subject_id: Union[\u001b[39mstr\u001b[39m, \u001b[39mint\u001b[39m],\n\u001b[1;32m    151\u001b[0m     session_nb: Union[\u001b[39mstr\u001b[39m, \u001b[39mint\u001b[39m],\n\u001b[1;32m    152\u001b[0m     device_name: \u001b[39mstr\u001b[39m,\n\u001b[1;32m    153\u001b[0m     experiment: \u001b[39mstr\u001b[39m,\n\u001b[1;32m    154\u001b[0m     replace_ch_names\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    155\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m    156\u001b[0m     site\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlocal\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    157\u001b[0m     data_dir\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    158\u001b[0m     inc_chans\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m--> 159\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m RawArray:\n\u001b[1;32m    160\u001b[0m     \u001b[39m\"\"\"Load CSV files from the /data directory into a Raw object.\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[39m    This is a utility function that simplifies access to eeg-notebooks\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39m    recordings by wrapping `load_csv_as_raw()`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[39m        (mne.io.RawArray): loaded EEG\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m    190\u001b[0m     subject_str \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m*\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m subject_id \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msubject\u001b[39m\u001b[39m{\u001b[39;00msubject_id\u001b[39m:\u001b[39;00m\u001b[39m04\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'RawArray' is not defined"
          ]
        }
      ],
      "source": [
        "# eegnb example data sites. do not select these when zipping recordings\n",
        "eegnb_sites = ['eegnb_examples', 'grifflab_dev', 'jadinlab_home']\n",
        "\n",
        "def fetch_dataset(\n",
        "    data_dir=None,\n",
        "    experiment=None,\n",
        "    site=\"eegnb_examples\",\n",
        "    device=\"muse2016\",\n",
        "    subjects=\"all\",\n",
        "    sessions=\"all\",\n",
        "    download_method=\"gdown\",\n",
        "):\n",
        "    \"\"\"\n",
        "    Return a long-form filenames list and a table saying what\n",
        "    subject and session, and run each entry corresponds to\n",
        "    Usage:\n",
        "            data_dir = '/my_folder'\n",
        "            experiment = 'visual-N170'\n",
        "            subjects = [1]\n",
        "            sessions = 'all'\n",
        "            visn170_fnames = fetch_dataset(data_dir=data_dir, subjects='all', experiment='visual-N170',\n",
        "            site='eegnb_examples')\n",
        "            visnP300_fnames = fetch_dataset(data_dir=data_dir, subjects=[1], experiment='visual-P300',\n",
        "            site='eegnb_examples')\n",
        "    \"\"\"\n",
        "    # List of experiments available\n",
        "    experiments_list = [\n",
        "        \"rest\",\n",
        "        \"auditory-P300\",\n",
        "        \"auditory-SSAEP\",\n",
        "        \"visual-cueing\",\n",
        "        \"visual-gonogo\",\n",
        "        \"visual-leftright\",\n",
        "        \"visual-N170\",\n",
        "        \"visual-P300\",\n",
        "        \"visual-spatialfreq\",\n",
        "        \"visual-SSVEP\",\n",
        "    ]\n",
        "\n",
        "    # List gdrive extensions for various experiments\n",
        "    gdrive_locs = {\n",
        "        \"visual-SSVEP\": \"1zj9Wx-YEMJo7GugUUu7Sshcybfsr-Fze\",\n",
        "        \"visual-spatialfreq\": \"1ggBt7CNvMgddxji-FvxcZoP-IF-PmESX\",\n",
        "        \"visual-P300\": \"1OLcj-zSjqdNrsBSUAsGBXOwWDnGWTVFC\",\n",
        "        \"visual-N170\": \"1oStfxzEqf36R5d-2Auyw4DLnPj9E_FAH\",\n",
        "        \"visual-leftright\": \"1f8A4Vbz0xjfgGIYFldMZ7ZL02x7T0jSt\",\n",
        "        \"visual-nogono\": \"1C8WKg9TXyp8A3QJ6T8zbGnk6jFcMutad\",\n",
        "        \"visual-cueing\": \"1ABOVJ9S0BeJOsqdGFnexaTFZ-ZcsIXfQ\",\n",
        "        \"auditory-SSAEP\": \"1fd0OAyNGWWOHD8e1FnEOLeQMeEoxqEpO\",\n",
        "        \"auditory-P300\": \"1OEtrRfMOkzDssGv-2Lj56FsArmPnQ2vD\",\n",
        "    }\n",
        "\n",
        "    # If no non-default top-level data path specified, use default\n",
        "    if data_dir == None:\n",
        "        data_dir = DATA_DIR\n",
        "\n",
        "    # check parameter entries\n",
        "    if experiment not in experiments_list:\n",
        "        raise ValueError(\"experiment not in database\")\n",
        "\n",
        "    # check if data has been previously downloaded\n",
        "    download_it = False\n",
        "    exp_dir = os.path.join(data_dir, experiment, site, device)\n",
        "    if not os.path.isdir(exp_dir):\n",
        "        download_it = True\n",
        "\n",
        "    if download_it:\n",
        "        # check if data directory exits. If not, create it\n",
        "        if os.path.exists(data_dir) is not True:\n",
        "            os.makedirs(data_dir)\n",
        "\n",
        "        destination = os.path.join(data_dir, \"downloaded_data.zip\")\n",
        "\n",
        "        if download_method == \"gdown\":\n",
        "\n",
        "            URL = \"https://drive.google.com/uc?id=\" + gdrive_locs[experiment]\n",
        "            gdown.download(URL, destination, quiet=False)\n",
        "\n",
        "        elif download_method == \"requests\":\n",
        "\n",
        "            URL = \"https://docs.google.com/uc?export=download\"\n",
        "\n",
        "            session = requests.Session()\n",
        "            response = session.get(\n",
        "                URL, params={\"id\": gdrive_locs[experiment]}, stream=True\n",
        "            )\n",
        "\n",
        "            # get the confirmation token to download large files\n",
        "            token = None\n",
        "            for key, value in response.cookies.items():\n",
        "                if key.startswith(\"download_warning\"):\n",
        "                    token = value\n",
        "\n",
        "            if token:\n",
        "                params = {\"id\": id, \"confirm\": token}\n",
        "                response = session.get(URL, params=params, stream=True)\n",
        "\n",
        "            # save content to the zip-file\n",
        "            CHUNK_SIZE = 32768\n",
        "            with open(destination, \"wb\") as f:\n",
        "                for chunk in response.iter_content(CHUNK_SIZE):\n",
        "                    if chunk:\n",
        "                        f.write(chunk)\n",
        "\n",
        "        # unzip the file\n",
        "        with zipfile.ZipFile(destination, \"r\") as zip_ref:\n",
        "            zip_ref.extractall(data_dir)\n",
        "\n",
        "        # remove the compressed zip archive\n",
        "        os.remove(destination)\n",
        "\n",
        "    if subjects == \"all\":\n",
        "        subjects = [\"*\"]\n",
        "    if sessions == \"all\":\n",
        "        sessions = [\"*\"]\n",
        "\n",
        "    # If 'all' subjects and 'all sesssions:\n",
        "    if (subjects[0] == \"*\") and (sessions[0] == \"*\"):\n",
        "        pth = os.path.join(\n",
        "            exp_dir, f\"subject{subjects[0]}\", f\"session{sessions[0]}\", \"*.csv\"\n",
        "        )\n",
        "        fnames = glob.glob(pth)\n",
        "    # Else, if specific subjects and sessions\n",
        "    else:\n",
        "        fnames = []\n",
        "        for subject_nb in subjects:\n",
        "            if subject_nb != \"*\":\n",
        "                # Format to get 4 digit number, e.g. 0004\n",
        "                subject_nb = float(subject_nb)\n",
        "                subject_nb = \"%03.f\" % subject_nb\n",
        "                for session_nb in sessions:\n",
        "                    # Formt to get 3 digit number, e.g. 003\n",
        "                    if session_nb != \"*\":\n",
        "                        session_nb = float(session_nb)\n",
        "                        session_nb = \"%02.f\" % session_nb\n",
        "\n",
        "                        pth = os.path.join(\n",
        "                            exp_dir,\n",
        "                            f\"subject{subject_nb}\",\n",
        "                            f\"session{session_nb}\",\n",
        "                            \"*.csv\",\n",
        "                        )\n",
        "                        # pth = '{}/subject{}/session{}/*.csv'.format(exp_dir,subject_nb, session_nb)\n",
        "                        fpaths = glob.glob(pth)\n",
        "                        fnames += fpaths\n",
        "\n",
        "    return fnames\n",
        "\n",
        "def load_data(\n",
        "    subject_id: Union[str, int],\n",
        "    session_nb: Union[str, int],\n",
        "    device_name: str,\n",
        "    experiment: str,\n",
        "    replace_ch_names=None,\n",
        "    verbose=1,\n",
        "    site=\"local\",\n",
        "    data_dir=None,\n",
        "    inc_chans=None,\n",
        ") -> RawArray:\n",
        "    \"\"\"Load CSV files from the /data directory into a Raw object.\n",
        "    This is a utility function that simplifies access to eeg-notebooks\n",
        "    recordings by wrapping `load_csv_as_raw()`.\n",
        "    The provided information is used to recover an eeg-notebooks recording file\n",
        "    path with the following structure:\n",
        "    data_dir/experiment/site/device_name/subject_str/session_str/<recording_date_time>.csv'\n",
        "    where <recording_date_time> is the automatically generated file name(s)\n",
        "    given at the time of recording.\n",
        "    Args:\n",
        "        subject_id (int or str): subject number. If 'all', load all\n",
        "            subjects.\n",
        "        session_nb (int or str): session number. If 'all', load all\n",
        "            sessions.\n",
        "        device_name (str): name of device. For a list of supported devices, see\n",
        "            eegnb.analysis.utils.SAMPLE_FREQS.\n",
        "        experiment (int or str): experiment name or number.\n",
        "        inc_chans (array_like): (Optional) Selective list of the number of the\n",
        "            channels to be imported\n",
        "    Keyword Args:\n",
        "        replace_ch_names (dict or None): dictionary containing a mapping to\n",
        "            rename channels. Useful when e.g., an external electrode was used.\n",
        "        verbose (int): verbose level.\n",
        "        site (str): site of recording. If 'all', data from all sites will be\n",
        "            used.\n",
        "        data_dir (str or None): directory inside /data that contains the\n",
        "            CSV files to load, e.g., 'auditory/'.\n",
        "    Returns:\n",
        "        (mne.io.RawArray): loaded EEG\n",
        "    \"\"\"\n",
        "\n",
        "    subject_str = \"*\" if subject_id == \"all\" else f\"subject{subject_id:04}\"\n",
        "    session_str = \"*\" if session_nb == \"all\" else f\"session{session_nb:03}\"\n",
        "    if site == \"all\":\n",
        "        site = \"*\"\n",
        "\n",
        "    data_path = (\n",
        "        _get_recording_dir(device_name, experiment, subject_str, session_str, site, data_dir)\n",
        "        / \"*.csv\"\n",
        "    )\n",
        "    fnames = glob(str(data_path))\n",
        "\n",
        "    sfreq = SAMPLE_FREQS[device_name]\n",
        "\n",
        "    ch_ind = EEG_INDICES[device_name]\n",
        "\n",
        "    if inc_chans is not None:\n",
        "        ch_ind = inc_chans\n",
        "\n",
        "    if device_name in [\"muse2016\", \"muse2\", \"museS\"]:\n",
        "        return load_csv_as_raw(\n",
        "            fnames,\n",
        "            sfreq=sfreq,\n",
        "            ch_ind=ch_ind,\n",
        "            aux_ind=[5],\n",
        "            replace_ch_names=replace_ch_names,\n",
        "            verbose=verbose,\n",
        "        )\n",
        "    else:\n",
        "        return load_csv_as_raw(\n",
        "            fnames,\n",
        "            sfreq=sfreq,\n",
        "            ch_ind=ch_ind,\n",
        "            replace_ch_names=replace_ch_names,\n",
        "            verbose=verbose,\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load Data\n",
        " ---------------------\n",
        "\n",
        " We will use the eeg-notebooks N170 example dataset\n",
        "\n",
        " Note that if you are running this locally, the following cell will download\n",
        " the example dataset, if you do not already have it.\n",
        "\n",
        "##################################################################################################\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1OLcj-zSjqdNrsBSUAsGBXOwWDnGWTVFC\n",
            "To: /Users/phily/eegnb/data/downloaded_data.zip\n",
            "100%|██████████| 18.4M/18.4M [00:01<00:00, 16.0MB/s]\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'load_data' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [12], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m subject \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     10\u001b[0m session \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m---> 11\u001b[0m raw \u001b[39m=\u001b[39m load_data(subject,session,\n\u001b[1;32m     12\u001b[0m                 experiment\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mvisual-P300\u001b[39m\u001b[39m'\u001b[39m, site\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39meegnb_examples\u001b[39m\u001b[39m'\u001b[39m, device_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmuse2016\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     13\u001b[0m                 data_dir \u001b[39m=\u001b[39m eegnb_data_path)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'load_data' is not defined"
          ]
        }
      ],
      "source": [
        "eegnb_data_path = os.path.join(os.path.expanduser('~/'),'eegnb', 'data')    \n",
        "p300_data_path = os.path.join(eegnb_data_path, 'visual-P300', 'eegnb_examples')\n",
        "\n",
        "# If dataset hasn't been downloaded yet, download it \n",
        "if not os.path.isdir(p300_data_path):\n",
        "    fetch_dataset(data_dir=eegnb_data_path, experiment='visual-P300', site='eegnb_examples');        \n",
        "\n",
        "\n",
        "subject = 1\n",
        "session = 1\n",
        "raw = load_data(subject,session,\n",
        "                experiment='visual-P300', site='eegnb_examples', device_name='muse2016',\n",
        "                data_dir = eegnb_data_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize the power spectrum\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "raw.plot_psd()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Filteriing\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "raw.filter(1,30, method='iir')\n",
        "raw.plot_psd(fmin=1, fmax=30);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Epoching\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Create an array containing the timestamps and type of each stimulus (i.e. face or house)\n",
        "events = find_events(raw)\n",
        "event_id = {'Non-Target': 1, 'Target': 2}\n",
        "epochs = Epochs(raw, events=events, event_id=event_id,\n",
        "                tmin=-0.1, tmax=0.8, baseline=None,                                                                                  \n",
        "                reject={'eeg': 100e-6}, preload=True,                                                                                  \n",
        "                verbose=False, picks=[0,1,2,3])\n",
        "\n",
        "print('sample drop %: ', (1 - len(epochs.events)/len(events)) * 100)\n",
        "\n",
        "epochs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Epoch average\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "conditions = OrderedDict()\n",
        "conditions['Non-target'] = [1]\n",
        "conditions['Target'] = [2]\n",
        "\n",
        "fig, ax = plot_conditions(epochs, conditions=conditions, \n",
        "                          ci=97.5, n_boot=1000, title='',\n",
        "                          diff_waveform=(1, 2))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10.6 ('p300bci')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "88aebea0dbeaca375ed1d45d0aed7bccd2899828f18a1ab77184ef6aec536d31"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
